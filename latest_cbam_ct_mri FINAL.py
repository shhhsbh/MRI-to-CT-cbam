# -*- coding: utf-8 -*-
"""latest_cbam_ct_mri.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18lIPhXBdydHqpheDoc3uE1Bmnxyx9h4Z
"""

import os

# Define the URL and output filename
zip_url = 'https://zenodo.org/records/7260705/files/Task1.zip'
zip_filename = 'Task1.zip'

# Download the zip file
!wget -O {zip_filename} {zip_url}

print(f"Downloaded {zip_filename}")

import zipfile

# Unzip the downloaded file
# This will create a 'Task1' directory with the dataset inside.
with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall('.')

print(f"Unzipped {zip_filename} into the current directory.")

# Verify the contents (optional, but good for debugging)
!ls Task1

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
import nibabel as nib
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
from skimage.metrics import peak_signal_noise_ratio as psnr_metric
from skimage.metrics import structural_similarity as ssim_metric

# --- Configuration ---
SEED = 42
def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(SEED)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# --- Mount Drive for Persistence ---
from google.colab import drive
drive.mount('/content/drive')

# --- Paths ---
# UPDATE THIS PATH to your actual data location
ROOT_DIR = "/content/Task1"
# Checkpoints will now be saved to Drive to persist after timeouts
CHECKPOINT_DIR = "/content/drive/MyDrive/Task1_Checkpoints"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# --- Physical Constants ---
MIN_HU = -1000
MAX_HU = 2000
# Scale used to denormalize for MAE calculation
HU_SCALE = (MAX_HU - MIN_HU) / 2

# --- Training Config ---
BATCH_SIZE = 1  # 3D models are memory hungry; often 1 or 2 is max
LR = 2e-4
EPOCHS = 100
TARGET_SHAPE = (128, 128, 128) # Crop size

# ==============================================================================
# UPDATED DATASET: Mask-Guided Cropping (Fixes Reviewer Point 3)
# ==============================================================================
class BrainMRICTDataset(Dataset):
    def __init__(self, patient_dirs, target_shape=(128, 128, 128), augment=False):
        self.patient_dirs = patient_dirs
        self.target_shape = target_shape
        self.augment = augment

    def __len__(self):
        return len(self.patient_dirs)

    def load_nii(self, path):
        # Load NIfTI and convert to float32
        return nib.load(path).get_fdata().astype(np.float32)

    def get_bbox_center(self, mask):
        """Find the center of mass of the binary mask."""
        coords = np.argwhere(mask > 0)
        if len(coords) == 0:
            # Fallback to image center if mask is empty
            return [s // 2 for s in mask.shape]

        min_coords = coords.min(axis=0)
        max_coords = coords.max(axis=0)
        center = (min_coords + max_coords) // 2
        return center

    def crop_around_center(self, vol, center):
        """Crop the volume around the specific center coordinate."""
        target = self.target_shape
        cur = vol.shape

        # Calculate start indices (top-left corner)
        start = [c - t // 2 for c, t in zip(center, target)]

        # Guard against out-of-bounds (negative start)
        start = [max(0, s) for s in start]

        # Guard against out-of-bounds (overflow end)
        end = [min(s + t, c) for s, t, c in zip(start, target, cur)]

        # Adjust start if end hit the boundary
        start = [e - t for e, t in zip(end, target)]
        start = [max(0, s) for s in start] # Double check

        sliced = vol[start[0]:end[0], start[1]:end[1], start[2]:end[2]]

        # Pad if the resulting slice is smaller than target (e.g. volume < 128)
        if sliced.shape != tuple(target):
            pad = [(0, t - s) for s, t in zip(sliced.shape, target)]
            sliced = np.pad(sliced, pad, mode='constant', constant_values=0)

        return sliced

    def __getitem__(self, idx):
        folder = self.patient_dirs[idx]

        # Load volumes
        mr = self.load_nii(os.path.join(folder, "mr.nii.gz"))
        ct = self.load_nii(os.path.join(folder, "ct.nii.gz"))

        # Load Mask (Assumes 'mask.nii.gz' exists as per reviewer comment)
        mask_path = os.path.join(folder, "mask.nii.gz")
        if os.path.exists(mask_path):
            mask = self.load_nii(mask_path)
            center = self.get_bbox_center(mask)
        else:
            # Fallback if mask missing
            center = [s // 2 for s in mr.shape]

        # Normalization
        mr = (mr - mr.mean()) / (mr.std() + 1e-8)
        ct = np.clip(ct, -1000, 2000)
        ct = 2 * (ct - (-1000)) / (2000 - (-1000)) - 1

        # Apply Mask-Guided Crop
        mr = self.crop_around_center(mr, center)
        ct = self.crop_around_center(ct, center)

        # Augmentation
        if self.augment:
            if random.random() > 0.5:
                axis = random.choice([0, 1, 2])
                mr = np.flip(mr, axis=axis).copy()
                ct = np.flip(ct, axis=axis).copy()

        return (
            torch.from_numpy(mr).unsqueeze(0).float(),
            torch.from_numpy(ct).unsqueeze(0).float(),
            os.path.basename(folder)
        )

class ChannelAttention3D(nn.Module):
    def __init__(self, in_planes, ratio=8):
        super(ChannelAttention3D, self).__init__()
        # avg/max pool over spatial dims (D, H, W) -> output (B, C, 1, 1, 1)
        self.avg_pool = nn.AdaptiveAvgPool3d(1)
        self.max_pool = nn.AdaptiveMaxPool3d(1)

        # Shared MLP
        # Reduction ratio must ensure at least 1 channel
        mid_planes = max(1, in_planes // ratio)

        self.mlp = nn.Sequential(
            nn.Conv3d(in_planes, mid_planes, 1, bias=False),
            nn.ReLU(),
            nn.Conv3d(mid_planes, in_planes, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.mlp(self.avg_pool(x))
        max_out = self.mlp(self.max_pool(x))
        out = avg_out + max_out
        return self.sigmoid(out) * x

class SpatialAttention3D(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention3D, self).__init__()
        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'
        padding = 3 if kernel_size == 7 else 1

        # Concat avg and max pool features (2 channels) -> Conv -> 1 channel
        self.conv1 = nn.Conv3d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x_cat = torch.cat([avg_out, max_out], dim=1)
        out = self.conv1(x_cat)
        return self.sigmoid(out) * x

class CBAM3D(nn.Module):
    def __init__(self, planes, ratio=8, kernel_size=7):
        super(CBAM3D, self).__init__()
        self.ca = ChannelAttention3D(planes, ratio)
        self.sa = SpatialAttention3D(kernel_size)

    def forward(self, x):
        out = self.ca(x)
        out = self.sa(out)
        return out

"""**A. Squeeze-and-Excitation (SE-Block 3D)**

SE focuses purely on channel relationships. It compresses the spatial dimensions (D, H, W) into a single vector and learns which channels are important.
"""

class SELayer3D(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SELayer3D, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool3d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1, 1)
        return x * y.expand_as(x)

"""**B. Coordinate Attention (CA-Block 3D)**

Standard CA (from CVPR 2021) is designed for 2D. For 3D Medical Imaging, we adapt it by pooling along the three cardinal directions (Depth, Height, Width) to capture long-range dependencies while preserving positional information.
"""

class CoordAtt3D(nn.Module):
    def __init__(self, inp, reduction=32):
        super(CoordAtt3D, self).__init__()
        # 1. Coordinate Pooling along D, H, and W
        self.pool_d = nn.AdaptiveAvgPool3d((None, 1, 1)) # Output: (B, C, D, 1, 1)
        self.pool_h = nn.AdaptiveAvgPool3d((1, None, 1)) # Output: (B, C, 1, H, 1)
        self.pool_w = nn.AdaptiveAvgPool3d((1, 1, None)) # Output: (B, C, 1, 1, W)

        mip = max(8, inp // reduction)

        # 2. Shared Convolution
        self.conv1 = nn.Conv3d(inp, mip, kernel_size=1, stride=1, padding=0)
        self.bn1 = nn.BatchNorm3d(mip)
        self.act = nn.Hardswish()

        # 3. Separate Convolutions for each axis
        self.conv_d = nn.Conv3d(mip, inp, kernel_size=1, stride=1, padding=0)
        self.conv_h = nn.Conv3d(mip, inp, kernel_size=1, stride=1, padding=0)
        self.conv_w = nn.Conv3d(mip, inp, kernel_size=1, stride=1, padding=0)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        identity = x
        n, c, d, h, w = x.size()

        # Pool
        x_d = self.pool_d(x)
        x_h = self.pool_h(x)
        x_w = self.pool_w(x)

        # Concatenate and Transform:
        # We process them separately to handle the varying D, H, W dimensions cleanly
        # Alternatively, we can permute and concat, but separate paths are clearer for 3D.

        y_d = self.act(self.bn1(self.conv1(x_d)))
        y_h = self.act(self.bn1(self.conv1(x_h)))
        y_w = self.act(self.bn1(self.conv1(x_w)))

        # Split and Expand
        a_d = self.sigmoid(self.conv_d(y_d))
        a_h = self.sigmoid(self.conv_h(y_h))
        a_w = self.sigmoid(self.conv_w(y_w))

        # Apply attention weights
        out = identity * a_d * a_h * a_w
        return out

class UNet3D_Ablation(nn.Module):
    def __init__(self, in_channels=1, out_channels=1, features=[16, 32, 64, 128], att_type='cbam'):
        super(UNet3D_Ablation, self).__init__()

        self.encoder = nn.ModuleList()
        self.att_blocks = nn.ModuleList()  # Changed name to generic 'att_blocks'
        self.pool = nn.MaxPool3d(2, 2)

        # --- Select Attention Module ---
        if att_type.lower() == 'se':
            AttBlock = SELayer3D
        elif att_type.lower() == 'ca':
            AttBlock = CoordAtt3D
        elif att_type.lower() == 'cbam':
            AttBlock = CBAM3D # Assumes CBAM3D is defined from previous cells
        else:
            raise ValueError("att_type must be 'se', 'ca', or 'cbam'")

        print(f"Initializing U-Net with {att_type.upper()} Attention")

        # --- Encoder ---
        input_c = in_channels
        for f in features:
            self.encoder.append(self.conv_block(input_c, f))
            # Instantiate the selected attention block
            self.att_blocks.append(AttBlock(f))
            input_c = f

        # --- Bottleneck ---
        self.bottleneck = self.conv_block(features[-1], features[-1] * 2)

        # --- Decoder ---
        self.upconvs = nn.ModuleList()
        self.decoder = nn.ModuleList()

        for f in reversed(features):
            self.upconvs.append(nn.ConvTranspose3d(f * 2, f, kernel_size=2, stride=2))
            self.decoder.append(self.conv_block(f * 2, f))

        self.final = nn.Conv3d(features[0], out_channels, kernel_size=1)

    def conv_block(self, in_c, out_c):
        return nn.Sequential(
            nn.Conv3d(in_c, out_c, kernel_size=3, padding=1),
            nn.InstanceNorm3d(out_c),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Conv3d(out_c, out_c, kernel_size=3, padding=1),
            nn.InstanceNorm3d(out_c),
            nn.LeakyReLU(0.1, inplace=True)
        )

    def forward(self, x):
        skips = []

        # Encoder Path
        for block, att in zip(self.encoder, self.att_blocks):
            x = block(x)
            x_att = att(x)  # Apply selected attention
            skips.append(x_att)
            x = self.pool(x)

        x = self.bottleneck(x)
        skips = skips[::-1]

        # Decoder Path
        for i, (up, dec) in enumerate(zip(self.upconvs, self.decoder)):
            x = up(x)
            x = torch.cat([x, skips[i]], dim=1)
            x = dec(x)

        return self.final(x)

def combined_loss(pred, target):
    # L1 Loss for pixel-wise accuracy, MSE for large errors
    return 0.5 * F.l1_loss(pred, target) + 0.5 * F.mse_loss(pred, target)

def denormalize_hu(tensor_img):
    """Convert [-1, 1] tensor back to HU scale numpy array"""
    # (B, C, D, H, W) -> numpy
    img = tensor_img.detach().cpu().numpy().squeeze()
    # Inverse of: 2 * (x - min) / (max - min) - 1
    # x = (y + 1) * (max - min) / 2 + min
    return (img + 1) * (MAX_HU - MIN_HU) / 2 + MIN_HU

# Scan directory
all_patients = []
# Assuming directory structure: ROOT_DIR/PatientID/mr.nii.gz
if os.path.exists(ROOT_DIR):
    for root, dirs, files in os.walk(ROOT_DIR):
        if "mr.nii.gz" in files and "ct.nii.gz" in files:
            all_patients.append(root)

print(f"Found {len(all_patients)} paired volumes.")

if len(all_patients) == 0:
    # Dummy data for code verification if files don't exist
    print("WARNING: No data found. Generating dummy data list.")
    all_patients = [f"dummy_{i}" for i in range(10)]
    # You would need to mock the Dataset.load_nii method to run without real files.

# 1. Define the Splits first (filenames only)
val_len = int(len(all_patients) * 0.15)
test_len = int(len(all_patients) * 0.15)
train_len = len(all_patients) - val_len - test_len

# Randomly split the list of IDs/paths
train_files, val_files, test_files = random_split(
    all_patients, [train_len, val_len, test_len],
    generator=torch.Generator().manual_seed(SEED)
)

# 2. Instantiate Datasets with different augment flags
# Train gets augmentation
train_ds = BrainMRICTDataset(train_files, target_shape=TARGET_SHAPE, augment=True)

# Val and Test do NOT get augmentation
val_ds = BrainMRICTDataset(val_files, target_shape=TARGET_SHAPE, augment=False)
test_ds = BrainMRICTDataset(test_files, target_shape=TARGET_SHAPE, augment=False)

# 3. Loaders
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)
test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)

print(f"Augmentation Enabled on Training Set: {len(train_ds)} samples")
print(f"Validation (No Aug): {len(val_ds)} samples")

# ... (After random_split) ...

print("\n" + "="*30)
print("DATA SPLIT REPORT (Copy to Appendix)")
print("="*30)

def get_ids(subset):
    return [os.path.basename(p) for p in subset.dataset.patient_dirs]

# Note: Subset doesn't expose raw list easily, so we access via indices if needed,
# but since we passed lists to random_split in the previous cell, we can just print those lists directly.
# Using the lists 'train_files', 'val_files', 'test_files' from the previous cell:

print(f"TRAIN IDs ({len(train_files)}):")
print([os.path.basename(f) for f in train_files])

print(f"\nVAL IDs ({len(val_files)}):")
print([os.path.basename(f) for f in val_files])

print(f"\nTEST IDs ({len(test_files)}):")
print([os.path.basename(f) for f in test_files])
print("="*30 + "\n")

# ==============================================================================
# 3. COMPLETE ABLATION LOOP (Training + Testing + CSV Saving) - FIXED VERSION
# ==============================================================================

import warnings
warnings.filterwarnings('ignore')

attention_types = ['se', 'ca', 'cbam']
all_histories = {}

for att in attention_types:
    print(f"\n{'='*20} Running Experiment: {att.upper()} {'='*20}")

    # --- 1. Setup ---
    save_dir = os.path.join(CHECKPOINT_DIR, f"model_{att}")
    os.makedirs(save_dir, exist_ok=True)

    # Initialize Model
    model = UNet3D_Ablation(att_type=att).to(device)

    # Optimizer & Scheduler
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

    # --- Resume Logic ---
    start_epoch = 0
    best_val_loss = float("inf")
    history = {'train_loss': [], 'val_loss': [], 'val_mae': []}

    ckpt_path = os.path.join(save_dir, "checkpoint_latest.pt")
    if os.path.exists(ckpt_path):
        print(f">>> Resuming {att.upper()} from checkpoint...")
        # üî¥ ÿßŸÑÿ≠ŸÑ ŸáŸÜÿß: ÿ•ÿ∂ÿßŸÅÿ© weights_only=False
        checkpoint = torch.load(ckpt_path, weights_only=False)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_val_loss = checkpoint['best_val_loss']
        history = checkpoint['history']
        print(f">>> Resumed from Epoch {start_epoch}")
    else:
        print(f">>> Starting new training for {att.upper()}")

    # --- 2. Training Loop ---
    if start_epoch < EPOCHS:
        for epoch in range(start_epoch, EPOCHS):
            # Training
            model.train()
            running_loss = 0.0

            pbar = tqdm(train_loader, desc=f"[{att.upper()}] Epoch {epoch+1}/{EPOCHS}", leave=False)
            for mri, ct, _ in pbar:
                mri, ct = mri.to(device), ct.to(device)

                optimizer.zero_grad()
                pred = model(mri)
                loss = combined_loss(pred, ct)
                loss.backward()
                optimizer.step()

                running_loss += loss.item()
                pbar.set_postfix({'loss': loss.item()})

            epoch_train_loss = running_loss / len(train_loader)

            # Validation
            model.eval()
            val_loss = 0.0
            mae_sum = 0.0

            with torch.no_grad():
                for mri, ct, _ in val_loader:
                    mri, ct = mri.to(device), ct.to(device)
                    pred = model(mri)

                    val_loss += combined_loss(pred, ct).item()

                    # Metric Calc
                    pred_hu = denormalize_hu(pred)
                    ct_hu = denormalize_hu(ct)
                    mae_sum += np.mean(np.abs(pred_hu - ct_hu))

            epoch_val_loss = val_loss / len(val_loader)
            epoch_mae = mae_sum / len(val_loader)

            # Store & Save
            history['train_loss'].append(epoch_train_loss)
            history['val_loss'].append(epoch_val_loss)
            history['val_mae'].append(epoch_mae)

            scheduler.step(epoch_val_loss)

            # Print only every epoch to reduce clutter
            print(f"Epoch {epoch+1} | Train: {epoch_train_loss:.4f} | Val: {epoch_val_loss:.4f} | MAE: {epoch_mae:.2f}")

            # Save Latest Checkpoint (for resuming) - ŸÖÿπ ÿ•ÿ∂ÿßŸÅÿ© numpy ŸÑŸÑŸÄ safe globals
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'best_val_loss': best_val_loss,
                'history': history
            }, ckpt_path)

            # Save Best Model (for testing)
            if epoch_val_loss < best_val_loss:
                best_val_loss = epoch_val_loss
                torch.save(model.state_dict(), os.path.join(save_dir, "best_model.pt"))
                print(f"    New Best Model Saved (Val Loss: {best_val_loss:.4f})")
    else:
        print(f">>> Training already completed for {att.upper()}")

    all_histories[att] = history

    # --- 3. Testing & CSV Generation ---
    print(f"\n>>> Generating Test Metrics for {att.upper()}...")

    # Load Best Weights
    best_model_path = os.path.join(save_dir, "best_model.pt")
    if os.path.exists(best_model_path):
        # üî¥ ÿ£Ÿäÿ∂ÿßŸã ŸáŸÜÿß ŸÜÿ∂ŸäŸÅ weights_only=False
        model.load_state_dict(torch.load(best_model_path, weights_only=False))
    else:
        print(f"Warning: No best model found for {att}, using current weights.")

    model.eval()

    test_results = {'MAE': [], 'PSNR': [], 'SSIM': [], 'ID': []}

    with torch.no_grad():
        for mri, ct, pid in tqdm(test_loader, desc=f"Testing {att.upper()}"):
            mri, ct = mri.to(device), ct.to(device)
            pred = model(mri)

            # De-normalize to HU
            pred_hu = denormalize_hu(pred)
            ct_hu = denormalize_hu(ct)

            # Calculate MAE
            mae = np.mean(np.abs(pred_hu - ct_hu))

            # Calculate PSNR/SSIM on normalized range
            pred_norm = pred.cpu().numpy().squeeze()
            ct_norm = ct.cpu().numpy().squeeze()

            val_psnr = psnr_metric(ct_norm, pred_norm, data_range=2.0)
            val_ssim = ssim_metric(ct_norm, pred_norm, data_range=2.0, channel_axis=None)

            test_results['MAE'].append(mae)
            test_results['PSNR'].append(val_psnr)
            test_results['SSIM'].append(val_ssim)
            test_results['ID'].append(pid[0])

    # Save CSV
    df = pd.DataFrame(test_results)
    csv_path = os.path.join(save_dir, "test_metrics.csv")
    df.to_csv(csv_path, index=False)
    print(f"Saved: {csv_path}")

print("\nAll experiments completed.")

# Visualize the last sample from the test loop with Error Map
mid_slice = ct_hu.shape[0] // 2

fig, ax = plt.subplots(1, 4, figsize=(20, 5))

# 1. MRI (Input)
mri_slice = mri.cpu().numpy().squeeze()[mid_slice]
ax[0].imshow(mri_slice, cmap='gray')
ax[0].set_title("Input MRI")
ax[0].axis('off')

# 2. Synthetic CT (Output)
# Use global min/max for consistent windowing
vmin, vmax = MIN_HU, MAX_HU
im2 = ax[1].imshow(pred_hu[mid_slice], cmap='gray', vmin=vmin, vmax=vmax)
ax[1].set_title(f"Synthetic CT\nMAE: {mae:.2f} HU")
ax[1].axis('off')

# 3. Real CT (Ground Truth)
ax[2].imshow(ct_hu[mid_slice], cmap='gray', vmin=vmin, vmax=vmax)
ax[2].set_title("Ground Truth CT")
ax[2].axis('off')

# 4. Difference Map
diff_map = np.abs(pred_hu[mid_slice] - ct_hu[mid_slice])
im4 = ax[3].imshow(diff_map, cmap='hot', vmin=0, vmax=500) # Cap heatmap at 500 HU error for visibility
ax[3].set_title("Absolute Error Map")
ax[3].axis('off')
plt.colorbar(im4, ax=ax[3], fraction=0.046, pad=0.04)

plt.tight_layout()
plt.show()

# Visualize Training History (Enhanced)
import matplotlib.pyplot as plt

# Use a cleaner style if available, else default
try:
    plt.style.use('seaborn-v0_8-whitegrid')
except:
    plt.style.use('default')

fig, axes = plt.subplots(1, 2, figsize=(18, 6))

# Plot 1: Validation Loss
for att in attention_types:
    if att in all_histories:
        hist = all_histories[att]
        epochs = range(1, len(hist['val_loss']) + 1)
        axes[0].plot(epochs, hist['val_loss'], label=f"{att.upper()} (Min: {min(hist['val_loss']):.4f})", linewidth=2)

axes[0].set_title("Validation Loss Convergence")
axes[0].set_xlabel("Epoch")
axes[0].set_ylabel("Loss")
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Plot 2: Validation MAE
for att in attention_types:
    if att in all_histories:
        hist = all_histories[att]
        epochs = range(1, len(hist['val_mae']) + 1)
        axes[1].plot(epochs, hist['val_mae'], label=f"{att.upper()} (Min: {min(hist['val_mae']):.2f})", linewidth=2)

axes[1].set_title("Validation MAE (HU)")
axes[1].set_xlabel("Epoch")
axes[1].set_ylabel("Mean Absolute Error")
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.suptitle("Training Dynamics Comparison", fontsize=16)
plt.tight_layout()
plt.show()

import seaborn as sns
from scipy.stats import ttest_rel, wilcoxon

# ==============================================================================
# STATISTICAL ANALYSIS & VISUALIZATION (Professional Report)
# ==============================================================================

# 1. Load Results
try:
    models = ['se', 'ca', 'cbam']
    data_frames = []

    for m in models:
        path = os.path.join(CHECKPOINT_DIR, f"model_{m}", "test_metrics.csv")
        if os.path.exists(path):
            df = pd.read_csv(path)
            df['Model'] = m.upper()
            df = df.sort_values('ID') # Ensure alignment
            data_frames.append(df)
        else:
            print(f"Warning: Results for {m} not found.")

    if not data_frames:
        raise FileNotFoundError("No results found. Run the training/testing loop first.")

    df_all = pd.concat(data_frames, ignore_index=True)

    # 2. Visual Comparison (Box Plots)
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    metrics = ['MAE', 'PSNR', 'SSIM']

    # Set style locally to avoid affecting global defaults if unwanted
    sns.set_style("whitegrid")

    for i, metric in enumerate(metrics):
        # Box plot shows distribution
        sns.boxplot(data=df_all, x='Model', y=metric, ax=axes[i], palette="Set2", showfliers=False)
        # Strip plot shows individual data points (good for transparency)
        sns.stripplot(data=df_all, x='Model', y=metric, ax=axes[i], color='black', alpha=0.3, jitter=True, size=4)
        axes[i].set_title(f"{metric} Distribution", fontsize=14)
        axes[i].set_xlabel("")

    plt.tight_layout()
    plt.show()

    # 3. Statistical Significance Tables
    print("\n" + "="*80)
    print("STATISTICAL SIGNIFICANCE REPORT (Paired Wilcoxon Signed-Rank Test)")
    print("="*80)

    # Pivot for paired access
    df_pivot = df_all.pivot(index='ID', columns='Model', values=metrics)

    # Define comparisons: Baseline vs Proposed
    comparisons = [('SE', 'CBAM'), ('CA', 'CBAM')]

    for metric in metrics:
        print(f"\n--- Metric: {metric} ---")
        print(f"{'Comparison':<20} | {'Mean Diff':<15} | {'p-value':<15} | {'Significance'}")
        print("-" * 75)

        for base, prop in comparisons:
            if base in df_pivot[metric].columns and prop in df_pivot[metric].columns:
                x = df_pivot[metric][base]
                y = df_pivot[metric][prop]

                # Test
                # Wilcoxon is safer for medical data which might not be perfectly normal
                stat, p = wilcoxon(x, y)
                mean_diff = y.mean() - x.mean()
                sig = "***" if p < 0.001 else "**" if p < 0.01 else "*" if p < 0.05 else "ns"

                print(f"{base} vs {prop:<10} | {mean_diff:<15.4f} | {p:<15.2e} | {sig}")

except Exception as e:
    print(f"Analysis Error: {e}\nMake sure you have trained and tested all models so the CSV files exist.")

CHECKPOINT_DIR = "/content/drive/MyDrive/Task1_Checkpoints"

attention_types = ['se', 'ca', 'cbam']
all_histories = {}

for att in attention_types:
    print(f"\n{'='*20} Running Experiment: {att.upper()} {'='*20}")

    # --- 1. Setup ---
    save_dir = os.path.join(CHECKPOINT_DIR, f"model_{att}")
    os.makedirs(save_dir, exist_ok=True)

"""# Task
Visualize the performance of the best model ('cbam') by examining specific cases.

First, load the `test_metrics.csv` file from the 'cbam' checkpoint directory. Sort the data to identify the Patient IDs with the **Best** (lowest MAE) and **Worst** (highest MAE) performance, and select one **Random** patient ID.

Next, load the best `UNet3D_Ablation` checkpoint for 'cbam'.

Finally, using the `test_dataset`, retrieve the data for these three specific patients. Run inference to generate the Synthetic CT, then create a figure for each patient containing four subplots:
1.  **Input MRI**
2.  **Synthetic CT** (Predicted)
3.  **Ground Truth CT**
4.  **Error Map** (Absolute difference between Predicted and Ground Truth)

Ensure all CT images are denormalized to Hounsfield Units (HU) for the visualization.

## Load Model for Analysis

### Subtask:
Load the best checkpoint for the 'cbam' model into the UNet3D_Ablation architecture to prepare for inference.

**Reasoning**:
Load the best CBAM model checkpoint for inference as requested in the subtask instructions.
"""

# Initialize the model with CBAM attention
model = UNet3D_Ablation(att_type='cbam')

# Construct the path to the best checkpoint
best_model_path = os.path.join(CHECKPOINT_DIR, "model_cbam", "best_model.pt")

# Load the checkpoint
if os.path.exists(best_model_path):
    # Load state dictionary with weights_only=False as per instructions/previous context
    state_dict = torch.load(best_model_path, map_location=device, weights_only=False)
    model.load_state_dict(state_dict)
    print(f"Successfully loaded best CBAM model from: {best_model_path}")
else:
    print(f"Warning: Best model not found at {best_model_path}")

# Move to device and set to evaluation mode
model.to(device)
model.eval()

"""# Task
Analyze the test metrics stored in "/content/drive/MyDrive/Task1_Checkpoints/model_cbam/test_metrics.csv" to identify the patients with the best (lowest MAE) and worst (highest MAE) performance, and select one random patient. Load the best 'cbam' model checkpoint from "/content/drive/MyDrive/Task1_Checkpoints/model_cbam/best_model.pt" and visualize these three cases in a 3x4 grid showing the Input MRI, Synthetic CT, Ground Truth, and Error Map.

## Inference and Metrics Collection

### Subtask:
Restore the environment by redefining necessary classes and loading the data/model, then load the test metrics.

**Reasoning**:
I need to restore the entire environment (classes, functions, constants, data loaders) because the runtime might have been reset or previous cells disconnected, causing the 'NameError'. I will redefine the dataset, model architectures (specifically CBAM and UNet), and the data loading logic to ensure the model can be loaded and inference can be run.
"""

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
import nibabel as nib
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
from skimage.metrics import peak_signal_noise_ratio as psnr_metric
from skimage.metrics import structural_similarity as ssim_metric

# --- Configuration ---
SEED = 42
def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(SEED)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# --- Paths & Constants ---
ROOT_DIR = "/content/Task1"
CHECKPOINT_DIR = "/content/drive/MyDrive/Task1_Checkpoints"
MIN_HU = -1000
MAX_HU = 2000
TARGET_SHAPE = (128, 128, 128)
BATCH_SIZE = 1

# --- Dataset Class ---
class BrainMRICTDataset(Dataset):
    def __init__(self, patient_dirs, target_shape=(128, 128, 128), augment=False):
        self.patient_dirs = patient_dirs
        self.target_shape = target_shape
        self.augment = augment

    def __len__(self):
        return len(self.patient_dirs)

    def load_nii(self, path):
        return nib.load(path).get_fdata().astype(np.float32)

    def get_bbox_center(self, mask):
        coords = np.argwhere(mask > 0)
        if len(coords) == 0:
            return [s // 2 for s in mask.shape]
        min_coords = coords.min(axis=0)
        max_coords = coords.max(axis=0)
        return (min_coords + max_coords) // 2

    def crop_around_center(self, vol, center):
        target = self.target_shape
        cur = vol.shape
        start = [max(0, c - t // 2) for c, t in zip(center, target)]
        end = [min(s + t, c) for s, t, c in zip(start, target, cur)]
        start = [max(0, e - t) for e, t in zip(end, target)]
        sliced = vol[start[0]:end[0], start[1]:end[1], start[2]:end[2]]
        if sliced.shape != tuple(target):
            pad = [(0, t - s) for s, t in zip(sliced.shape, target)]
            sliced = np.pad(sliced, pad, mode='constant', constant_values=0)
        return sliced

    def __getitem__(self, idx):
        folder = self.patient_dirs[idx]
        mr = self.load_nii(os.path.join(folder, "mr.nii.gz"))
        ct = self.load_nii(os.path.join(folder, "ct.nii.gz"))
        mask_path = os.path.join(folder, "mask.nii.gz")

        if os.path.exists(mask_path):
            mask = self.load_nii(mask_path)
            center = self.get_bbox_center(mask)
        else:
            center = [s // 2 for s in mr.shape]

        mr = (mr - mr.mean()) / (mr.std() + 1e-8)
        ct = np.clip(ct, -1000, 2000)
        ct = 2 * (ct - (-1000)) / (2000 - (-1000)) - 1

        mr = self.crop_around_center(mr, center)
        ct = self.crop_around_center(ct, center)

        return (
            torch.from_numpy(mr).unsqueeze(0).float(),
            torch.from_numpy(ct).unsqueeze(0).float(),
            os.path.basename(folder)
        )

# --- Model Classes (CBAM + UNet) ---
class ChannelAttention3D(nn.Module):
    def __init__(self, in_planes, ratio=8):
        super(ChannelAttention3D, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool3d(1)
        self.max_pool = nn.AdaptiveMaxPool3d(1)
        mid_planes = max(1, in_planes // ratio)
        self.mlp = nn.Sequential(
            nn.Conv3d(in_planes, mid_planes, 1, bias=False),
            nn.ReLU(),
            nn.Conv3d(mid_planes, in_planes, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.mlp(self.avg_pool(x))
        max_out = self.mlp(self.max_pool(x))
        return self.sigmoid(avg_out + max_out) * x

class SpatialAttention3D(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention3D, self).__init__()
        padding = 3 if kernel_size == 7 else 1
        self.conv1 = nn.Conv3d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x_cat = torch.cat([avg_out, max_out], dim=1)
        return self.sigmoid(self.conv1(x_cat)) * x

class CBAM3D(nn.Module):
    def __init__(self, planes, ratio=8, kernel_size=7):
        super(CBAM3D, self).__init__()
        self.ca = ChannelAttention3D(planes, ratio)
        self.sa = SpatialAttention3D(kernel_size)

    def forward(self, x):
        return self.sa(self.ca(x))

class UNet3D_Ablation(nn.Module):
    def __init__(self, in_channels=1, out_channels=1, features=[16, 32, 64, 128], att_type='cbam'):
        super(UNet3D_Ablation, self).__init__()
        self.encoder = nn.ModuleList()
        self.att_blocks = nn.ModuleList()
        self.pool = nn.MaxPool3d(2, 2)

        if att_type.lower() == 'cbam':
            AttBlock = CBAM3D
        else:
            # Placeholder if other types needed, but focusing on CBAM for restoration
            AttBlock = CBAM3D

        input_c = in_channels
        for f in features:
            self.encoder.append(self.conv_block(input_c, f))
            self.att_blocks.append(AttBlock(f))
            input_c = f

        self.bottleneck = self.conv_block(features[-1], features[-1] * 2)
        self.upconvs = nn.ModuleList()
        self.decoder = nn.ModuleList()
        for f in reversed(features):
            self.upconvs.append(nn.ConvTranspose3d(f * 2, f, kernel_size=2, stride=2))
            self.decoder.append(self.conv_block(f * 2, f))
        self.final = nn.Conv3d(features[0], out_channels, kernel_size=1)

    def conv_block(self, in_c, out_c):
        return nn.Sequential(
            nn.Conv3d(in_c, out_c, kernel_size=3, padding=1),
            nn.InstanceNorm3d(out_c),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Conv3d(out_c, out_c, kernel_size=3, padding=1),
            nn.InstanceNorm3d(out_c),
            nn.LeakyReLU(0.1, inplace=True)
        )

    def forward(self, x):
        skips = []
        for block, att in zip(self.encoder, self.att_blocks):
            x = block(x)
            x = att(x)
            skips.append(x)
            x = self.pool(x)
        x = self.bottleneck(x)
        skips = skips[::-1]
        for i, (up, dec) in enumerate(zip(self.upconvs, self.decoder)):
            x = up(x)
            x = torch.cat([x, skips[i]], dim=1)
            x = dec(x)
        return self.final(x)

def denormalize_hu(tensor_img):
    img = tensor_img.detach().cpu().numpy().squeeze()
    return (img + 1) * (MAX_HU - MIN_HU) / 2 + MIN_HU

# --- Data Loader Setup ---
all_patients = []
if os.path.exists(ROOT_DIR):
    for root, dirs, files in os.walk(ROOT_DIR):
        if "mr.nii.gz" in files and "ct.nii.gz" in files:
            all_patients.append(root)

if len(all_patients) == 0:
    print("WARNING: No data found. Ensure dataset is unzipped.")
else:
    val_len = int(len(all_patients) * 0.15)
    test_len = int(len(all_patients) * 0.15)
    train_len = len(all_patients) - val_len - test_len
    _, _, test_files = random_split(
        all_patients, [train_len, val_len, test_len],
        generator=torch.Generator().manual_seed(SEED)
    )
    test_ds = BrainMRICTDataset(test_files, target_shape=TARGET_SHAPE, augment=False)
    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)
    print(f"Test Set Re-initialized: {len(test_ds)} samples")

# --- Model Loading ---
model = UNet3D_Ablation(att_type='cbam').to(device)
best_model_path = os.path.join(CHECKPOINT_DIR, "model_cbam", "best_model.pt")
if os.path.exists(best_model_path):
    state_dict = torch.load(best_model_path, map_location=device, weights_only=False)
    model.load_state_dict(state_dict)
    model.eval()
    print(f"Loaded model from {best_model_path}")
else:
    print(f"Warning: Checkpoint not found at {best_model_path}")

# --- Metrics Loading ---
csv_path = os.path.join(CHECKPOINT_DIR, "model_cbam", "test_metrics.csv")
if os.path.exists(csv_path):
    test_df = pd.read_csv(csv_path)
    print("Test metrics loaded.")
    print(test_df.head())
else:
    print("Metrics file not found. Running inference to generate metrics...")
    # Fallback: Run inference if CSV missing
    results = {'MAE': [], 'PSNR': [], 'SSIM': [], 'ID': []}
    with torch.no_grad():
        for mri, ct, pid in tqdm(test_loader):
            mri, ct = mri.to(device), ct.to(device)
            pred = model(mri)
            pred_hu = denormalize_hu(pred)
            ct_hu = denormalize_hu(ct)
            mae = np.mean(np.abs(pred_hu - ct_hu))
            pred_norm = pred.cpu().numpy().squeeze()
            ct_norm = ct.cpu().numpy().squeeze()
            val_psnr = psnr_metric(ct_norm, pred_norm, data_range=2.0)
            val_ssim = ssim_metric(ct_norm, pred_norm, data_range=2.0, channel_axis=None)
            results['MAE'].append(mae)
            results['PSNR'].append(val_psnr)
            results['SSIM'].append(val_ssim)
            results['ID'].append(pid[0])
    test_df = pd.DataFrame(results)
    test_df.to_csv(csv_path, index=False)
    print(f"Metrics generated and saved to {csv_path}")

"""**Reasoning**:
The previous execution failed with a `NameError` because `test_loader` was not defined when no data was found in `ROOT_DIR`, but the code attempted to iterate over it in the metrics generation fallback block. I will initialize `test_loader` to `None` before the data checking logic and add a check ensuring `test_loader` exists before attempting inference.


"""

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
import nibabel as nib
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
from skimage.metrics import peak_signal_noise_ratio as psnr_metric
from skimage.metrics import structural_similarity as ssim_metric

# --- Configuration ---
SEED = 42
def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(SEED)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# --- Paths & Constants ---
ROOT_DIR = "/content/Task1"
CHECKPOINT_DIR = "/content/drive/MyDrive/Task1_Checkpoints"
MIN_HU = -1000
MAX_HU = 2000
TARGET_SHAPE = (128, 128, 128)
BATCH_SIZE = 1

# --- Dataset Class ---
class BrainMRICTDataset(Dataset):
    def __init__(self, patient_dirs, target_shape=(128, 128, 128), augment=False):
        self.patient_dirs = patient_dirs
        self.target_shape = target_shape
        self.augment = augment

    def __len__(self):
        return len(self.patient_dirs)

    def load_nii(self, path):
        return nib.load(path).get_fdata().astype(np.float32)

    def get_bbox_center(self, mask):
        coords = np.argwhere(mask > 0)
        if len(coords) == 0:
            return [s // 2 for s in mask.shape]
        min_coords = coords.min(axis=0)
        max_coords = coords.max(axis=0)
        return (min_coords + max_coords) // 2

    def crop_around_center(self, vol, center):
        target = self.target_shape
        cur = vol.shape
        start = [max(0, c - t // 2) for c, t in zip(center, target)]
        end = [min(s + t, c) for s, t, c in zip(start, target, cur)]
        start = [max(0, e - t) for e, t in zip(end, target)]
        sliced = vol[start[0]:end[0], start[1]:end[1], start[2]:end[2]]
        if sliced.shape != tuple(target):
            pad = [(0, t - s) for s, t in zip(sliced.shape, target)]
            sliced = np.pad(sliced, pad, mode='constant', constant_values=0)
        return sliced

    def __getitem__(self, idx):
        folder = self.patient_dirs[idx]
        mr = self.load_nii(os.path.join(folder, "mr.nii.gz"))
        ct = self.load_nii(os.path.join(folder, "ct.nii.gz"))
        mask_path = os.path.join(folder, "mask.nii.gz")

        if os.path.exists(mask_path):
            mask = self.load_nii(mask_path)
            center = self.get_bbox_center(mask)
        else:
            center = [s // 2 for s in mr.shape]

        mr = (mr - mr.mean()) / (mr.std() + 1e-8)
        ct = np.clip(ct, -1000, 2000)
        ct = 2 * (ct - (-1000)) / (2000 - (-1000)) - 1

        mr = self.crop_around_center(mr, center)
        ct = self.crop_around_center(ct, center)

        return (
            torch.from_numpy(mr).unsqueeze(0).float(),
            torch.from_numpy(ct).unsqueeze(0).float(),
            os.path.basename(folder)
        )

# --- Model Classes (CBAM + UNet) ---
class ChannelAttention3D(nn.Module):
    def __init__(self, in_planes, ratio=8):
        super(ChannelAttention3D, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool3d(1)
        self.max_pool = nn.AdaptiveMaxPool3d(1)
        mid_planes = max(1, in_planes // ratio)
        self.mlp = nn.Sequential(
            nn.Conv3d(in_planes, mid_planes, 1, bias=False),
            nn.ReLU(),
            nn.Conv3d(mid_planes, in_planes, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.mlp(self.avg_pool(x))
        max_out = self.mlp(self.max_pool(x))
        return self.sigmoid(avg_out + max_out) * x

class SpatialAttention3D(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention3D, self).__init__()
        padding = 3 if kernel_size == 7 else 1
        self.conv1 = nn.Conv3d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x_cat = torch.cat([avg_out, max_out], dim=1)
        return self.sigmoid(self.conv1(x_cat)) * x

class CBAM3D(nn.Module):
    def __init__(self, planes, ratio=8, kernel_size=7):
        super(CBAM3D, self).__init__()
        self.ca = ChannelAttention3D(planes, ratio)
        self.sa = SpatialAttention3D(kernel_size)

    def forward(self, x):
        return self.sa(self.ca(x))

class UNet3D_Ablation(nn.Module):
    def __init__(self, in_channels=1, out_channels=1, features=[16, 32, 64, 128], att_type='cbam'):
        super(UNet3D_Ablation, self).__init__()
        self.encoder = nn.ModuleList()
        self.att_blocks = nn.ModuleList()
        self.pool = nn.MaxPool3d(2, 2)

        if att_type.lower() == 'cbam':
            AttBlock = CBAM3D
        else:
            # Placeholder if other types needed, but focusing on CBAM for restoration
            AttBlock = CBAM3D

        input_c = in_channels
        for f in features:
            self.encoder.append(self.conv_block(input_c, f))
            self.att_blocks.append(AttBlock(f))
            input_c = f

        self.bottleneck = self.conv_block(features[-1], features[-1] * 2)
        self.upconvs = nn.ModuleList()
        self.decoder = nn.ModuleList()
        for f in reversed(features):
            self.upconvs.append(nn.ConvTranspose3d(f * 2, f, kernel_size=2, stride=2))
            self.decoder.append(self.conv_block(f * 2, f))
        self.final = nn.Conv3d(features[0], out_channels, kernel_size=1)

    def conv_block(self, in_c, out_c):
        return nn.Sequential(
            nn.Conv3d(in_c, out_c, kernel_size=3, padding=1),
            nn.InstanceNorm3d(out_c),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Conv3d(out_c, out_c, kernel_size=3, padding=1),
            nn.InstanceNorm3d(out_c),
            nn.LeakyReLU(0.1, inplace=True)
        )

    def forward(self, x):
        skips = []
        for block, att in zip(self.encoder, self.att_blocks):
            x = block(x)
            x = att(x)
            skips.append(x)
            x = self.pool(x)
        x = self.bottleneck(x)
        skips = skips[::-1]
        for i, (up, dec) in enumerate(zip(self.upconvs, self.decoder)):
            x = up(x)
            x = torch.cat([x, skips[i]], dim=1)
            x = dec(x)
        return self.final(x)

def denormalize_hu(tensor_img):
    img = tensor_img.detach().cpu().numpy().squeeze()
    return (img + 1) * (MAX_HU - MIN_HU) / 2 + MIN_HU

# --- Data Loader Setup ---
all_patients = []
test_loader = None  # <--- Initialize variable to None to prevent NameError

if os.path.exists(ROOT_DIR):
    for root, dirs, files in os.walk(ROOT_DIR):
        if "mr.nii.gz" in files and "ct.nii.gz" in files:
            all_patients.append(root)

if len(all_patients) == 0:
    print("WARNING: No data found. Ensure dataset is unzipped.")
else:
    val_len = int(len(all_patients) * 0.15)
    test_len = int(len(all_patients) * 0.15)
    train_len = len(all_patients) - val_len - test_len
    _, _, test_files = random_split(
        all_patients, [train_len, val_len, test_len],
        generator=torch.Generator().manual_seed(SEED)
    )
    test_ds = BrainMRICTDataset(test_files, target_shape=TARGET_SHAPE, augment=False)
    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)
    print(f"Test Set Re-initialized: {len(test_ds)} samples")

# --- Model Loading ---
model = UNet3D_Ablation(att_type='cbam').to(device)
best_model_path = os.path.join(CHECKPOINT_DIR, "model_cbam", "best_model.pt")
if os.path.exists(best_model_path):
    state_dict = torch.load(best_model_path, map_location=device, weights_only=False)
    model.load_state_dict(state_dict)
    model.eval()
    print(f"Loaded model from {best_model_path}")
else:
    print(f"Warning: Checkpoint not found at {best_model_path}")

# --- Metrics Loading ---
csv_path = os.path.join(CHECKPOINT_DIR, "model_cbam", "test_metrics.csv")
if os.path.exists(csv_path):
    test_df = pd.read_csv(csv_path)
    print("Test metrics loaded.")
    print(test_df.head())
else:
    print("Metrics file not found. Running inference to generate metrics...")
    # Fallback: Run inference if CSV missing
    if test_loader is None:
        print("Error: test_loader is not defined (no data found). Cannot generate metrics.")
        # Create dummy df to prevent crashes downstream if needed, or just let it fail gracefully
        test_df = pd.DataFrame(columns=['MAE', 'PSNR', 'SSIM', 'ID'])
    else:
        results = {'MAE': [], 'PSNR': [], 'SSIM': [], 'ID': []}
        with torch.no_grad():
            for mri, ct, pid in tqdm(test_loader):
                mri, ct = mri.to(device), ct.to(device)
                pred = model(mri)
                pred_hu = denormalize_hu(pred)
                ct_hu = denormalize_hu(ct)
                mae = np.mean(np.abs(pred_hu - ct_hu))
                pred_norm = pred.cpu().numpy().squeeze()
                ct_norm = ct.cpu().numpy().squeeze()
                val_psnr = psnr_metric(ct_norm, pred_norm, data_range=2.0)
                val_ssim = ssim_metric(ct_norm, pred_norm, data_range=2.0, channel_axis=None)
                results['MAE'].append(mae)
                results['PSNR'].append(val_psnr)
                results['SSIM'].append(val_ssim)
                results['ID'].append(pid[0])
        test_df = pd.DataFrame(results)
        test_df.to_csv(csv_path, index=False)
        print(f"Metrics generated and saved to {csv_path}")

"""**Reasoning**:
The previous execution failed to load data and checkpoints because the environment was missing the dataset and likely didn't have Google Drive mounted. I will generate a code block to: 1. Mount Google Drive. 2. Download and unzip the dataset if missing. 3. Re-initialize the `test_loader` with the newly available data. 4. Reload the model weights (now that Drive is mounted). 5. Load or regenerate the test metrics DataFrame. This effectively completes the restoration subtask.


"""

import os
import zipfile
import torch
import pandas as pd
from google.colab import drive
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm

# 1. Mount Drive to access checkpoints
if not os.path.exists('/content/drive'):
    print("Mounting Drive...")
    drive.mount('/content/drive')

# 2. Check for Data and Download if missing
ROOT_DIR = "/content/Task1"
if not os.path.exists(ROOT_DIR):
    print("Data not found. Downloading...")
    !wget -O Task1.zip https://zenodo.org/records/7260705/files/Task1.zip
    print("Unzipping...")
    with zipfile.ZipFile("Task1.zip", 'r') as zip_ref:
        zip_ref.extractall('.')
    print("Data downloaded and unzipped.")
else:
    print("Data directory exists.")

# 3. Re-initialize Loader
all_patients = []
for root, dirs, files in os.walk(ROOT_DIR):
    if "mr.nii.gz" in files and "ct.nii.gz" in files:
        all_patients.append(root)

print(f"Found {len(all_patients)} patients.")

if len(all_patients) > 0:
    val_len = int(len(all_patients) * 0.15)
    test_len = int(len(all_patients) * 0.15)
    train_len = len(all_patients) - val_len - test_len
    # Use same seed to ensure split consistency
    _, _, test_files = random_split(
        all_patients, [train_len, val_len, test_len],
        generator=torch.Generator().manual_seed(42)
    )
    # Assuming BrainMRICTDataset, TARGET_SHAPE, device, etc. are defined in previous cell
    test_ds = BrainMRICTDataset(test_files, target_shape=TARGET_SHAPE, augment=False)
    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)
    print(f"Test Loader initialized: {len(test_ds)} samples.")
else:
    test_loader = None
    print("Error: No patients found.")

# 4. Load Model
CHECKPOINT_DIR = "/content/drive/MyDrive/Task1_Checkpoints"
best_model_path = os.path.join(CHECKPOINT_DIR, "model_cbam", "best_model.pt")

if 'UNet3D_Ablation' in globals():
    model = UNet3D_Ablation(att_type='cbam').to(device)
    if os.path.exists(best_model_path):
        state_dict = torch.load(best_model_path, map_location=device, weights_only=False)
        model.load_state_dict(state_dict)
        model.eval()
        print(f"Model loaded from {best_model_path}")
    else:
        print(f"Warning: Checkpoint not found at {best_model_path}. Model initialized with random weights.")
else:
    print("Model class not defined. Please ensure previous setup cell ran successfully.")

# 5. Load or Generate Metrics
csv_path = os.path.join(CHECKPOINT_DIR, "model_cbam", "test_metrics.csv")
if os.path.exists(csv_path):
    test_df = pd.read_csv(csv_path)
    print("Test metrics loaded from CSV.")
else:
    print("Metrics CSV not found. Generating...")
    if test_loader is not None:
        results = {'MAE': [], 'PSNR': [], 'SSIM': [], 'ID': []}
        with torch.no_grad():
            for mri, ct, pid in tqdm(test_loader, desc="Generating Metrics"):
                mri, ct = mri.to(device), ct.to(device)
                pred = model(mri)

                # Calculate Metrics
                pred_hu = denormalize_hu(pred)
                ct_hu = denormalize_hu(ct)
                mae = np.mean(np.abs(pred_hu - ct_hu))

                pred_norm = pred.cpu().numpy().squeeze()
                ct_norm = ct.cpu().numpy().squeeze()
                val_psnr = psnr_metric(ct_norm, pred_norm, data_range=2.0)
                val_ssim = ssim_metric(ct_norm, pred_norm, data_range=2.0, channel_axis=None)

                results['MAE'].append(mae)
                results['PSNR'].append(val_psnr)
                results['SSIM'].append(val_ssim)
                results['ID'].append(pid[0])

        test_df = pd.DataFrame(results)
        if os.path.exists(CHECKPOINT_DIR):
             test_df.to_csv(csv_path, index=False)
             print(f"Metrics saved to {csv_path}")
        else:
             print("Checkpoint dir not found (Drive issue?), metrics not saved to disk.")
    else:
        test_df = pd.DataFrame(columns=['MAE', 'PSNR', 'SSIM', 'ID'])
        print("Empty DataFrame created because no data loaded.")

print(test_df.head())

